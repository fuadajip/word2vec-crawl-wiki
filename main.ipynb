{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT = 'output.txt'\n",
    "DEFAULT_INTERVAL = 5.0  # interval between requests (seconds)\n",
    "DEFAULT_ARTICLES_LIMIT = 1  # total number articles to be extrated\n",
    "USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'\n",
    "\n",
    "\n",
    "visited_urls = set()  # all urls already visited, to not visit twice\n",
    "pending_urls = []  # queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_urls(session_file):\n",
    "    \"\"\"Resume previous session if any, load visited URLs\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(session_file) as fin:\n",
    "            for line in fin:\n",
    "                visited_urls.add(line.strip())\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(base_url, article, output_file, session_file):\n",
    "    \"\"\"Represents one request per article\"\"\"\n",
    "\n",
    "    full_url = base_url + article\n",
    "    try:\n",
    "        r = requests.get(full_url, headers={'User-Agent': USER_AGENT})\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Check your Internet connection\")\n",
    "        input(\"Press [ENTER] to continue to the next request.\")\n",
    "        return\n",
    "    if r.status_code not in (200, 404):\n",
    "        print(\"Failed to request page (code {})\".format(r.status_code))\n",
    "        input(\"Press [ENTER] to continue to the next request.\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    content = soup.find('div', {'id':'mw-content-text'})\n",
    "\n",
    "    with open(session_file, 'a') as fout:\n",
    "        fout.write(full_url + '\\n')  # log URL to session file\n",
    "\n",
    "    # add new related articles to queue\n",
    "    # check if are actual articles URL\n",
    "    for a in content.find_all('a'):\n",
    "        href = a.get('href')\n",
    "        if not href:\n",
    "            continue\n",
    "        if href[0:6] != '/wiki/':  # allow only article pages\n",
    "            continue\n",
    "        elif ':' in href:  # ignore special articles e.g. 'Special:'\n",
    "            continue\n",
    "        elif href[-4:] in \".png .jpg .jpeg .svg\":  # ignore image files inside articles\n",
    "            continue\n",
    "        elif base_url + href in visited_urls:  # already visited\n",
    "            continue\n",
    "        if href in pending_urls:  # already added to queue\n",
    "            continue\n",
    "        pending_urls.append(href)\n",
    "\n",
    "    # skip if already added text from this article, as continuing session\n",
    "    if full_url in visited_urls:\n",
    "        return\n",
    "    visited_urls.add(full_url)\n",
    "\n",
    "    parenthesis_regex = re.compile('\\(.+?\\)')  # to remove parenthesis content\n",
    "    citations_regex = re.compile('\\[.+?\\]')  # to remove citations, e.g. [1]\n",
    "\n",
    "    # get plain text from each <p>\n",
    "    p_list = content.find_all('p')\n",
    "    with open(output_file, 'a') as fout:\n",
    "        for p in p_list:\n",
    "            text = p.get_text().strip()\n",
    "            text = parenthesis_regex.sub('', text)\n",
    "            text = citations_regex.sub('', text)\n",
    "            if text:\n",
    "                fout.write(text + '\\n\\n')  # extra line between paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(initial_url, articles_limit, interval, output_file):\n",
    "    \"\"\" Main loop, single thread \"\"\"\n",
    "\n",
    "    minutes_estimate = interval * articles_limit / 60\n",
    "    print(\"This session will take {:.1f} minute(s) to download {} article(s):\".format(minutes_estimate, articles_limit))\n",
    "    print(\"\\t(Press CTRL+C to pause)\\n\")\n",
    "    session_file = \"session_\" + output_file\n",
    "    load_urls(session_file)  # load previous session (if any)\n",
    "    base_url = '{uri.scheme}://{uri.netloc}'.format(uri=urlparse(initial_url))\n",
    "    initial_url = initial_url[len(base_url):]\n",
    "    pending_urls.append(initial_url)\n",
    "\n",
    "    counter = 0\n",
    "    while len(pending_urls) > 0:\n",
    "        try:\n",
    "            counter += 1\n",
    "            if counter > articles_limit:\n",
    "                break\n",
    "            try:\n",
    "                next_url = pending_urls.pop(0)\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "            time.sleep(interval)\n",
    "            article_format = next_url.replace('/wiki/', '')[:35]\n",
    "            print(\"{:<7} {}\".format(counter, article_format))\n",
    "            scrap(base_url, next_url, output_file, session_file)\n",
    "        except KeyboardInterrupt:\n",
    "            input(\"\\n> PAUSED. Press [ENTER] to continue...\\n\")\n",
    "            counter -= 1\n",
    "\n",
    "    print(\"Finished!\")\n",
    "    sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session will take 8.3 minute(s) to download 100 article(s):\n",
      "\t(Press CTRL+C to pause)\n",
      "\n",
      "1       Pornografi\n",
      "2       Usia_dewasa\n",
      "3       Penyensoran\n",
      "4       Sunat\n",
      "5       Pernikahan_sejenis\n",
      "6       Tari_telanjang\n",
      "7       Yurisdiksi\n",
      "8       Perselingkuhan\n",
      "9       Perawatan_anak\n",
      "10      Pornografi_anak-anak\n",
      "11      Pelacuran_anak\n",
      "12      Hubungan_sedarah\n",
      "13      Pelacuran\n",
      "14      Pedofilia\n",
      "15      Pemerkosaan\n",
      "16      Pemerkosaan#Statutory_rape\n",
      "17      Pemerkosaan#Pemerkosaan_oleh_suami.\n",
      "18      Sexting\n",
      "19      Pelecehan_seksual_terhadap_anak\n",
      "20      Perbudakan_seksual\n",
      "21      Pelecehan_seksual\n",
      "22      Zoofilia\n",
      "23      Sodomi\n",
      "24      Homoseksualitas\n",
      "25      Wikisource\n",
      "26      Bahasa_Yunani\n",
      "27      Tubuh_manusia\n",
      "28      Perilaku\n",
      "29      Seksualitas_manusia\n",
      "30      Berahi\n",
      "31      Erotika\n",
      "32      Erotisme\n",
      "33      Eufemisme\n",
      "34      Foto\n",
      "35      Ukiran\n",
      "36      Gambar\n",
      "37      Animasi\n",
      "38      Suara\n",
      "39      Film_porno\n",
      "40      Majalah\n",
      "41      Novel\n",
      "42      Cerita_pendek\n",
      "43      Pelacur\n",
      "44      Yunani_kuno\n",
      "45      Ilmu_sosial\n",
      "46      Abad_ke-18\n",
      "47      Abad_ke-19\n",
      "48      Oxford_English_Dictionary\n",
      "49      1905\n",
      "50      Michelangelo\n",
      "51      Ketelanjangan\n",
      "52      Alat_kelamin\n",
      "53      Penetrasi\n",
      "54      Paleolitik\n",
      "55      Kekaisaran_Romawi\n",
      "56      Pompeii\n",
      "57      Jerman\n",
      "58      Adonis\n",
      "59      1920-an\n",
      "60      Playboy\n",
      "61      Abad_ke-20\n",
      "62      1950-an\n",
      "63      Masturbasi\n",
      "64      1960-an\n",
      "65      1990-an\n",
      "66      Film\n",
      "67      Prancis\n",
      "68      1908\n",
      "69      Fellatio\n",
      "70      Seks_anal\n",
      "71      1970\n",
      "72      New_York_Times\n",
      "73      Perekam_kaset_video\n",
      "74      Traci_Lords\n",
      "75      Betamax\n",
      "76      VHS\n",
      "77      HD-DVD\n",
      "78      Adobe_Photoshop\n",
      "79      2000-an\n",
      "80      2004\n",
      "81      Tokoh_fiksi\n",
      "82      Lara_Croft\n",
      "83      Oktober\n",
      "84      Telanjang_dada\n",
      "85      Internet\n",
      "86      Permainan_video\n",
      "87      Pornografi_internet\n",
      "88      Kazaa\n",
      "89      Pornografi_anak\n",
      "90      Larry_Flynt\n",
      "91      Salman_Rushdie\n",
      "92      Pornografi_di_Indonesia\n",
      "93      Amerika_Serikat\n",
      "94      Australia\n",
      "95      John_Howard\n",
      "96      Wilayah_Utara\n",
      "97      ACT\n",
      "98      Kekerasan\n",
      "99      Austria\n",
      "100     Telanjang\n",
      "Finished!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda2/envs/MachineLearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    " main(\"https://id.wikipedia.org/wiki/Pornografi\", 100 , 5, \"Output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
